{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bambani2003/Data_Science_Projects/blob/main/NLP/Comment_Toxicity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BylFvRue8Ikr"
      },
      "source": [
        "# **Using NLP to identify toxic comments.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required modules\n",
        "\n",
        "!pip install gradio jinja2"
      ],
      "metadata": {
        "id": "fFfN_hRfbtvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmlVnMOx5PRs"
      },
      "outputs": [],
      "source": [
        "# Import the required modules\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding\n",
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using GPU with TensorFlow\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if len(device_name) > 0:\n",
        "    print(\"Found GPU at: {}\".format(device_name))\n",
        "else:\n",
        "    device_name = \"/device:CPU:0\"\n",
        "    print(\"No GPU, using {}.\".format(device_name))"
      ],
      "metadata": {
        "id": "7tjS24VhiGAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA**"
      ],
      "metadata": {
        "id": "2NNNGgeXoWFl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGgF_LFg9m45"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "\n",
        "df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSets/Toxic_Comments/train.csv')\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "NtGoX5gOobQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our training data\n",
        "\n",
        "x_train = df['comment_text'].values\n",
        "y_train = df[df.columns[2:]].values\n",
        "display(x_train)\n",
        "display(y_train)"
      ],
      "metadata": {
        "id": "3LQZLeWf-r3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our vectoriser to tokenise the words\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=len(x_train), output_sequence_length=1500, output_mode='int')\n",
        "vectorizer.adapt(x_train)\n",
        "vectorizer.get_vocabulary()"
      ],
      "metadata": {
        "id": "ynd5Llq8rbB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at the tokenised comments\n",
        "\n",
        "vectorized_text = vectorizer(x_train)\n",
        "vectorized_text"
      ],
      "metadata": {
        "id": "EEJf9Mi_spnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipelining the training data for our model\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y_train))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(150000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8)\n",
        "dataset.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "lGNznLkEug3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CV and Test data pipeline\n",
        "\n",
        "train = dataset.take(int(len(dataset)*0.7))\n",
        "cross_val = dataset.skip(int(len(dataset)*0.7)).take(int(len(dataset)*0.2))\n",
        "test = dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1))"
      ],
      "metadata": {
        "id": "mFzlk9yEgr4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MACHINE LEARNING**"
      ],
      "metadata": {
        "id": "FLF6qcsVeLIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "\n",
        "with tf.device(device_name):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(x_train)+1, 32))\n",
        "    model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "    model.add(Dense(48, activation='relu'))\n",
        "    model.add(Dense(96, activation='relu'))\n",
        "    model.add(Dense(48, activation='relu'))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(12, activation='relu'))\n",
        "    model.add(Dense(6, activation='sigmoid'))\n",
        "    model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
      ],
      "metadata": {
        "id": "pldz63j3deO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the model\n",
        "\n",
        "history = model.fit(train, epochs=10, validation_data=cross_val)"
      ],
      "metadata": {
        "id": "BMRIIaqkZJuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for the training and CV loss (No use for only 1 epoch)\n",
        "\n",
        "plt.figure(figsize = (8, 5))\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n3jq0iAbZ2Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUTAION**"
      ],
      "metadata": {
        "id": "_PxLk8khan0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Precision, Recall and Overall Accuracy of the model\n",
        "\n",
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()\n",
        "for batch in dataset.as_numpy_iterator():\n",
        "    X_true, y_true = batch\n",
        "    yhat = model.predict(X_true)\n",
        "    y_true = y_true.flatten()\n",
        "    yhat = yhat.flatten()\n",
        "    pre.update_state(y_true, yhat)\n",
        "    re.update_state(y_true, yhat)\n",
        "    acc.update_state(y_true, yhat)\n",
        "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ],
      "metadata": {
        "id": "YxyA0AyGat63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREDICTIONS**"
      ],
      "metadata": {
        "id": "fg9vD8iubAjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Given an input, check if it is some form of toxic\n",
        "\n",
        "text = input()\n",
        "input_text = vectorizer(text)\n",
        "res = model.predict(np.expand_dims(input_text, 0))\n",
        "(res > 0.5).astype(int)\n",
        "batch_X, batch_y = test.as_numpy_iterator().next()\n",
        "(model.predict(batch_X) > 0.5).astype(int)\n",
        "res.shape"
      ],
      "metadata": {
        "id": "hmC24drYbEN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TESTING using UI**"
      ],
      "metadata": {
        "id": "ZxgVdu0FblCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model for later use\n",
        "\n",
        "model.save('NLP_Comment_Toxicity.h5')\n",
        "model = tf.keras.models.load_model('NLP_Comment_Toxicity.h5')"
      ],
      "metadata": {
        "id": "1sUxAAnobqbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the expanded dimensional output\n",
        "\n",
        "input_str = vectorizer('I freaking hate you!')\n",
        "res = model.predict(np.expand_dims(input_str,0))\n",
        "res"
      ],
      "metadata": {
        "id": "4EHNIfRdcSRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gradio and HuggingFace to create a UI\n",
        "\n",
        "def score_comment(comment):\n",
        "    vectorized_comment = vectorizer([comment])\n",
        "    results = model.predict(vectorized_comment)\n",
        "\n",
        "    text = ''\n",
        "    for idx, col in enumerate(df.columns[2:]):\n",
        "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
        "\n",
        "    return text\n",
        "interface = gr.Interface(fn=score_comment, inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'), outputs='text')\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "id": "CYYe53sEgH_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1MPCdTmdYBpCwvcSDI9bjAMJWB2dJC_er",
      "authorship_tag": "ABX9TyOCCsyqV3S1E+W1MQGm909G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}